{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04992286",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from src.data_import import load_data\n",
    "from src.data_cleaning import select_columns, strip_spaces_columns, normalize_case_columns, gene_filter, convert_numeric_columns, drop_missing_required, check_influence_cooks_distance\n",
    "from src.statistical_analysis import factor_categorical\n",
    "from src.app_logger import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec1d7a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'check_influence_cooks_distance' from 'src.data_cleaning' (/Users/carolfarah/final_projext_yas/final_project/src/data_cleaning.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_import\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_data\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_cleaning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m select_columns, strip_spaces_columns, normalize_case_columns, gene_filter, convert_numeric_columns, drop_missing_required, check_influence_cooks_distance\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstatistical_analysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m factor_categorical\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapp_logger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logger\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'check_influence_cooks_distance' from 'src.data_cleaning' (/Users/carolfarah/final_projext_yas/final_project/src/data_cleaning.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from src.data_import import load_data\n",
    "from src.data_cleaning import select_columns, strip_spaces_columns, normalize_case_columns, gene_filter, convert_numeric_columns, drop_missing_required, check_influence_cooks_distance\n",
    "from src.statistical_analysis import factor_categorical\n",
    "from src.app_logger import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed568f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = [\"Patient_ID\", \"Gene/Factor\", \"Disease_Stage\", \"Brain_Volume_Loss\", \"Age\", \"Sex\"]\n",
    "\n",
    "sub_df = select_columns(df, columns_list) #Columns from original df were selected\n",
    "sub_df = strip_spaces_columns(sub_df, columns=[\"Gene/Factor\", \"Disease_Stage\", \"Sex\"])\n",
    "sub_df = normalize_case_columns(sub_df, columns= [\"Gene/Factor\", \"Disease_Stage\", \"Sex\"])\n",
    "sub_df = gene_filter(sub_df, \"Gene/Factor\", values_list= [\"mlh1\", \"msh3\", \"htt (somatic expansion)\"])\n",
    "sub_df = drop_missing_required(sub_df, columns_list)\n",
    "clean_df, removed_rows, threshold= check_influence_cooks_distance(sub_df, \"Brain_Volume_Loss\", \"Age\", \"Sex\")\n",
    "sub_df = factor_categorical(sub_df, \"Disease_Stage\", \"Sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b820db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.statistical_assumptions import check_independence_duplicates, plot_ancova_linearity, drop_duplicate_subjects, levene_two_way_anova, levene_ancova, check_linearity_age_dv, log_transform, check_homogeneity_of_slopes\n",
    "from src.data_visualization import plot_ancova_linearity\n",
    "independence_test = check_independence_duplicates(sub_df, \"Patient_ID\")\n",
    "if independence_test.empty:\n",
    "    print(\"No duplicates, observations are all independent\")\n",
    "else:\n",
    "    print(f\"Duplicates detected! There are {len(independence_test)/2}\")\n",
    "    sub_df = drop_duplicate_subjects(sub_df, \"Patient_ID\", keep= \"first\")\n",
    "    print(f\"{len(independence_test)/2} rows removed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4bfbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "linearity_check = check_linearity_age_dv(df, dv=\"Brain_Volume_Loss\", cov=\"Age\", show_plot=True)\n",
    "linearity_check_p_value = linearity_check[\"p_value\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d92af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ancova_levene_stat, ancova_levene_p = levene_ancova(sub_df, \"Brain_Volume_Loss\", \"Disease_Stage\", \"Age\", center='median')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1a5425",
   "metadata": {},
   "outputs": [],
   "source": [
    "ancova_linearity_graphs = plot_ancova_linearity(sub_df, dv=\"Brain_Volume_Loss\", iv=\"Disease_Stage\", cov=\"Age\")\n",
    "\n",
    "while True:\n",
    "    transform_dataset = input(\"Does dataset require transformation? (yes/no): \").strip().lower()\n",
    "    \n",
    "    if transform_dataset in {\"yes\", \"no\"}:\n",
    "        break\n",
    "    else:\n",
    "        print(\"Please enter 'yes' or 'no'.\")\n",
    "\n",
    "if transform_dataset == \"yes\":\n",
    "    clean_df = log_transform(clean_df, \"Brain_Volume_Loss\", new_column = \"Brain_Volume_Loss\") #replaces values with new values after transformation\n",
    "    clean_df = log_transform(clean_df, \"Age\", new_column = \"Age\")\n",
    "    ancova_linearity_graphs = plot_ancova_linearity(sub_df, dv=\"Brain_Volume_Loss\", iv=\"Disease_Stage\", cov=\"Age\")\n",
    "else:\n",
    "    print(\"Proceeding with assumptions analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea70ae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "homogeneity_of_slopes_table = check_homogeneity_of_slopes(sub_df, \"Brain_Volume_Loss\", \"Disease_Stage\", \"Age\")\n",
    "p_val_homogeneity_of_slopes= anova_table.loc[\"C(Disease_Stage):Age\", \"PR(>F)\"]\n",
    "\n",
    "p_iv  = ancova_table.loc[\"C(Disease_Stage)\", \"PR(>F)\"]\n",
    "p_cov = ancova_table.loc[\"Age\", \"PR(>F)\"]\n",
    "\n",
    "iv_sig  = p_iv  < 0.05\n",
    "cov_sig = p_cov < 0.05\n",
    "\n",
    "from src.statistical_analysis import run_ancova, run_ancova_with_statsmodels_posthoc, run_moderated_regression\n",
    "\n",
    "if p_val_homogeneity_of_slopes > 0.05:\n",
    "    print(\"The effect of the covariate Age are the same on the level of IV Disease_Stage.\\n Conducting ANCOVA\")\n",
    "    ancova_test_model, ancova_test_table = run_ancova(sub_df, \"Brain_Volume_Loss\", \"Disease_Stage\", \"Age\", ancova_levene_p, linearity_check_p_value, alpha=0.05)\n",
    "    if not iv_sig and not cov_sig:\n",
    "        print(\"An ANCOVA revealed no significant effect of disease stage on brain volume loss, controlling for age,\" \\\n",
    "        \"nor was age significantly associated with brain volume loss.\\n\")\n",
    "\n",
    "    elif iv_sig and not cov_sig:\n",
    "        print(\"An ANCOVA revealed a significant effect of disease stage on brain volume loss, \" \\\n",
    "        f\"controlling for age p = {p_iv}, ηp² = {ancova_table_table.iloc[0][\"partial_eta_sq\"]}. Age was not significantly associated with brain volume loss.\")\n",
    "        print(\"\\nPost-hoc pairwise comparisons of adjusted means were conducted using Bonferroni correction.\")\n",
    "        run_posthoc = True\n",
    "\n",
    "    elif not iv_sig and cov_sig:\n",
    "        print(\"An ANCOVA revealed no significant effect of disease stage on brain volume loss after controlling for age. \" \\\n",
    "        f\"Age was significantly associated with brain volume loss, p = {ancova_table_table.iloc[1][\"PR(>F)\"]}.\")\n",
    "\n",
    "    else:\n",
    "        print(\"An ANCOVA revealed a significant effect of disease stage on brain volume loss, \" \\\n",
    "        f\"controlling for age, F(df₁, df₂) = X.XX, p = {p_iv}, ηp² = {ancova_table_table.iloc[0][\"partial_eta_sq\"]}.\" \\ \n",
    "        f\"Age was also significantly associated with brain volume loss, F(1, df₂) = X.XX, p = {p_cov}.\")\n",
    "        print(\"\\nPost-hoc pairwise comparisons of adjusted means were conducted using Bonferroni correction.\")\n",
    "        run_posthoc = True\n",
    "\n",
    "    if run_posthoc = True:\n",
    "        print(\"\\nPost-hoc pairwise comparisons were conducted using Bonferroni correction.\")\n",
    "        ancova_post_hoc = run_ancova_with_statsmodels_posthoc(sub_df, \"Brain_Volume_Loss\", \"Disease_Stage\", \"Age\", alpha=0.05)\n",
    "    \n",
    "    print(\"The results of the post-hoc are as follows:\\n\" + ancova_post_hoc)\n",
    "else: #Moderated regression\n",
    "    print(\"The effect of the covariate Age differs depending on the level of IV Disease_Stage.\\n Conducting moderated regression instead\")\n",
    "    moderated_regression_results = run_moderated_regression(sub_df, \"Brain_Volume_Loss\", \"Disease_Stage\", \"Age\")\n",
    "\n",
    "    if \"IV:Covariate\" in moderated_regression_results.index and moderated_regression_results.loc[\"IV:Covariate\", \"P>|t|\"] < 0.05:\n",
    "    print(\"Interaction significant \\nRunning spotlight/simple slopes at ±1 SD of Covariate\")\n",
    "    spotlight_analysis_results = run_spotlight_analysis(sub_df, \"Brain_Volume_Loss\", \"Disease_Stage\", \"Age\")\n",
    "\n",
    "    print(\"Spotlight Analysis (Simple Slopes)\\n\")\n",
    "    print(spotlight_analysis_results)\n",
    "\n",
    "    elif \"IV\" in moderated_regression_results.index and moderated_regression_results.loc[\"IV\", \"P>|t|\"] < 0.05:\n",
    "    if df[iv].nunique() > 2:\n",
    "        print(\"IV main effect significant\\n running pairwise post-hoc comparisons between IV levels\")\n",
    "    else:\n",
    "        print(\"IV main effect significant\\n post-hoc needed (only 2 levels)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951dca22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
